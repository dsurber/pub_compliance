{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from Bio import Entrez\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from redcap import Project\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "### Get access keys from the setup file - config.py\n",
    "import config\n",
    "import pub_comp_lib\n",
    "\n",
    "# ## !!** For DEV\n",
    "from importlib import reload\n",
    "# reload(name_of_module)\n",
    "# ## !!** For DEV\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"test.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\"\n",
    "    )\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "#logger = logging.basicConfig(filename='app.log', filemode='w',\n",
    "#                             format='%(name)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pub_comp_lib.py libraries\n",
    "from Bio import Entrez\n",
    "from Bio.Entrez import efetch\n",
    "from Bio.Entrez import read\n",
    "import regex as re\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all config grants for cleanup\n",
    "for x in range(len(config.grant_list)):\n",
    "    # remove all whitespace, leading or trailing hyphenates - clean_grant.py\n",
    "    config.grant_list[x] = pub_comp_lib.clean(config.grant_list[x])\n",
    "\n",
    "### Create list for each grant with 34 grant variations - grant_vari.py\n",
    "variations = []\n",
    "for grant in config.grant_list:\n",
    "    variations.extend(pub_comp_lib.variety(grant))\n",
    "\n",
    "### Get pmids from pubmed for all grant variations\n",
    "# create variables for pubmed queries\n",
    "Entrez.email = \"Your.Name.Here@example.org\"\n",
    "Entrez.api_key = config.ncbi_api\n",
    "\n",
    "# create set for unique list of all pmids from querying pubmed with each\n",
    "# grant variation\n",
    "pmids = set()\n",
    "# query pubmed for pmids associated with each grant variation\n",
    "logger.info(\"Starting pubmed queries...\")\n",
    "pubmed_results = []\n",
    "\n",
    "for grant in variations:\n",
    "    attempt = 1\n",
    "    while attempt <= 3:\n",
    "        try:\n",
    "            handle = Entrez.esearch(db='pubmed', term=grant,\n",
    "                                    field='grant', retmax=5000,\n",
    "                                    usehistory='y', retmode='xml')\n",
    "            record = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            if int(record['Count']) > 0:\n",
    "                pubmed_results.append(record)\n",
    "                pmids.update(record['IdList'])\n",
    "                logger.info('Entrez ESearch returns %i Ids for %s' % (int(record['Count']), str(grant)))\n",
    "            attempt = 4\n",
    "        except Exception as err:\n",
    "            logger.warning('Received error from server: %s' % str(err))\n",
    "            logger.warning('Attempt %i of 3 for grant %s.' % (attempt,\n",
    "                                                              str(grant)))\n",
    "            attempt += 1\n",
    "            time.sleep(2)\n",
    "    logger.debug('Grant %s queried.' % str(grant))\n",
    "\n",
    "logger.info('All grant queries complete.')\n",
    "\n",
    "##### To test for PubMed downtime or blocked access...\n",
    "#handle = Entrez.esearch(db='pubmed', term=grant[0], field='grant')\n",
    "#record = Entrez.read(handle)\n",
    "#handle.close()\n",
    "#print(record)\n",
    "\n",
    "### Update pmid set if a REDCap project is being used to track publications\n",
    "if config.rc_token is not None and config.rc_uri is not None:\n",
    "    old_pmids = []\n",
    "    # get the full pmid list from the REDCap project\n",
    "    project = Project(config.rc_uri, config.rc_token)\n",
    "    rc_pmids = project.export_records(fields=['pmid'], format='json')\n",
    "    for rc_pmid in rc_pmids:\n",
    "        old_pmids.append(rc_pmid['pmid'])\n",
    "    new_pmids = list(pmids.difference(old_pmids))   # newly discovered pmids\n",
    "    pmids.update(old_pmids)\n",
    "    # date of first discovery\n",
    "    if len(new_pmids) > 0:\n",
    "        first_disc = [datetime.date.today().strftime(\"%Y-%m-%d\")]*len(new_pmids)\n",
    "        # create data frame of new_pmids with date of first dicovery and\n",
    "        # import into REDCap project\n",
    "        # create data frame using lists and import into redcap\n",
    "        first_discovered_frame = pd.DataFrame(np.column_stack([new_pmids, first_disc]),\n",
    "                            columns=['pmid', 'first_discovered'])\n",
    "        response = project.import_records(first_discovered_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### PubMed Summary Section\n",
    "### Get table of publication details from pubmed for pmids\n",
    "# make dataframe of publications\n",
    "pubs_frame = pub_comp_lib.summary(pmids, config.ncbi_api, variations)\n",
    "# add compliant pmc status for publications with a pmcid\n",
    "pubs_frame['pmc_status'] = np.where(pubs_frame.pmcid == '', '', '1')\n",
    "# write table\n",
    "pubs_frame.to_csv('batch_pubmed_frame.csv', index=False)\n",
    "\n",
    "# change blank values to nan- makes column merging easier\n",
    "pubs_frame[pubs_frame == ''] = np.nan\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "pubs_frame = pubs_frame.rename(columns={'pmcid':'pmc_id', 'nihmsid':'nihms_id'})\n",
    "###################### END PubMed Summary Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### To test for PubMed downtime or blocked access...\n",
    "#handle = Entrez.esearch(db='pubmed', term=grant[0], field='grant')\n",
    "#record = Entrez.read(handle)\n",
    "#handle.close()\n",
    "#print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload(pub_comp_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Development section\n",
    "pubs_frame['pub_date'] = pd.to_datetime(pubs_frame['pub_date'], format='%Y-%m-%d')\n",
    "status_pmc = pubs_frame.pmid\n",
    "status_pmc.to_csv('pmids_to_check_in_pmc.csv', index=False)\n",
    "\n",
    "delay = 2\n",
    "long_delay = 7\n",
    "pmc_rows = []\n",
    "start = 0\n",
    "scrape_more = 1\n",
    "#test_pmc = ['31443893', '31280053', '30968993', '31568479', '31390231', '31161938']\n",
    "####################### Development section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########!!!!!!***** Dev interrupt and jump off point\n",
    "driver = pub_comp_lib.ncbi_login(config.ncbi_login, config.ncbi_pass)\n",
    "driver.get('https://www.ncbi.nlm.nih.gov/myncbi/collections/mybibliography/')\n",
    "pub_comp_lib.clear_my_bib(driver, delay, logger)\n",
    "pub_comp_lib.add_to_my_bib(driver, status_pmc[0:51], delay, long_delay, logger)\n",
    "time.sleep(delay)\n",
    "driver.get('https://www.ncbi.nlm.nih.gov/myncbi/collections/mybibliography/')\n",
    "time.sleep(delay)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "cites = soup.find_all('div', 'citation-wrap')\n",
    "\n",
    "\n",
    "#status_pmc = pubs_frame.pmid[0:1100]\n",
    "##########!!!!!!*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "pmc_rows = []\n",
    "print(len(pmc_rows))\n",
    "print(len(cites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pmc_rows.append(pub_comp_lib.scrape_citations(cites[0], 0, variations, driver, delay, long_delay, logger, start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(cites)):\n",
    "    pmc_rows.append(pub_comp_lib.scrape_citations(cites[x], x, variations, driver, delay, long_delay, logger, start))\n",
    "## check if there's another page of citations to scrape\n",
    "time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[['31688933', '1', '', ['K76 AG060005'], 0], ['31919777', '1', 'UL1 TR002373', ['R01 HD047516', 'UL1 TR002373'], 1], ['29112024', '4', '', [], 2], ['32034257', '1', '', [], 3]]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(type(pmc_rows))\n",
    "print (pmc_rows[0:4])\n",
    "print(len(pmc_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    next_button = driver.find_element_by_xpath('//*[@id=\"pager1\"]/ul/li[4]/a').get_attribute('onclick')\n",
    "except Exception as err:\n",
    "    next_button = 'return false;'\n",
    "print(next_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if next_button == 'return false;' or driver.find_element_by_xpath('//*[@id=\"pager2\"]/ul/li/span').get_attribute('innerText') == '1':\n",
    "    scrape_more = 0\n",
    "else: driver.find_element_by_xpath('//*[@id=\"pager1\"]/ul/li[4]/a').click()\n",
    "print(scrape_more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[['31688933', '1', '', ['K76 AG060005'], 0], ['31919777', '1', 'UL1 TR002373', ['R01 HD047516', 'UL1 TR002373'], 1], ['29112024', '4', '', [], 2], ['32034257', '1', '', [], 3]]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(type(pmc_rows))\n",
    "print (pmc_rows[0:4])\n",
    "print(len(pmc_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "cites = soup.find_all('div', 'citation-wrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(pmc_rows))\n",
    "print(len(cites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(cites)):\n",
    "    pmc_rows.append(pub_comp_lib.scrape_citations(cites[x], x, variations, driver, delay, long_delay, logger, start))\n",
    "## check if there's another page of citations to scrape\n",
    "time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[['31688933', '1', '', ['K76 AG060005'], 0], ['31919777', '1', 'UL1 TR002373', ['R01 HD047516', 'UL1 TR002373'], 1], ['29112024', '4', '', [], 2], ['32034257', '1', '', [], 3]]\n",
      "51\n",
      "['18788956', '1', 'KL2 RR025012', ['KL2 RR025012'], 0]\n"
     ]
    }
   ],
   "source": [
    "print(type(pmc_rows))\n",
    "print (pmc_rows[0:4])\n",
    "print(len(pmc_rows))\n",
    "print(pmc_rows[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return false;\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    next_button = driver.find_element_by_xpath('//*[@id=\"pager1\"]/ul/li[4]/a').get_attribute('onclick')\n",
    "except Exception as err:\n",
    "    next_button = 'return false;'\n",
    "print(next_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if next_button == 'return false;' or driver.find_element_by_xpath('//*[@id=\"pager2\"]/ul/li/span').get_attribute('innerText') == '1':\n",
    "    scrape_more = 0\n",
    "else: driver.find_element_by_xpath('//*[@id=\"pager1\"]/ul/li[4]/a').click()\n",
    "print(scrape_more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_more == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2864"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(status_pmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!!!!!!!!! DEV ONLY \n",
    "\n",
    "##*** Dev only variables\n",
    "start = 0\n",
    "count = 0\n",
    "#status_pmc = pubs_frame.pmid[0:249]\n",
    "\n",
    "##*** Dev only variables\n",
    "\n",
    "\n",
    "pmc_rows = []\n",
    "batch_size = 250\n",
    "count = len(status_pmc)\n",
    "delay = 2\n",
    "long_delay = 7\n",
    "\n",
    "#for start in range(0, count, batch_size):\n",
    "end = min(count, start+batch_size)\n",
    "\n",
    "# reload my bib, clear all publications and load pmids in status_pmc\n",
    "driver.get('https://www.ncbi.nlm.nih.gov/myncbi/collections/mybibliography/')\n",
    "pub_comp_lib.clear_my_bib(driver, delay, logger)\n",
    "pub_comp_lib.add_to_my_bib(driver, status_pmc[start:end], delay, long_delay, logger)\n",
    "# reload my bib and begin scraping each page of citations\n",
    "time.sleep(delay)\n",
    "driver.get('https://www.ncbi.nlm.nih.gov/myncbi/collections/mybibliography/')\n",
    "time.sleep(delay)\n",
    "scrape_more = 1\n",
    "\n",
    "##!!!!!!!!! DEV ONLY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!!!!!!!!! DEV ONLY \n",
    "\n",
    "#### loop for each 'next page' click\n",
    "#while scrape_more == 1:\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "cites = soup.find_all('div', 'citation-wrap')\n",
    "for x in range(len(cites)):\n",
    "    pmc_rows.append(pub_comp_lib.scrape_citations(cites[x], x, variations, driver, delay, long_delay, logger, start))\n",
    "## check if there's another page of citations to scrape\n",
    "time.sleep(delay)\n",
    "try:\n",
    "    next_button = driver.find_element_by_xpath('//*[@id=\"pager1\"]/ul/li[4]/a').get_attribute('onclick')\n",
    "except Exception as err:\n",
    "    next_button = 'return false;'\n",
    "if next_button == 'return false;' or driver.find_element_by_xpath('//*[@id=\"pager2\"]/ul/li/span').get_attribute('innerText') == '1':\n",
    "    scrape_more = 0\n",
    "else: driver.find_element_by_xpath('//*[@id=\"pager1\"]/ul/li[4]/a').click()\n",
    "if count > 1000:\n",
    "    time.sleep(90)\n",
    "    print('Working on ' + str(start) + ' : ' + str(end) + '    minutes-{0:0.1f}' .format((time.time()-start_time)/60))\n",
    "##!!!!!!!!! DEV ONLY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!!!!!!!!! DEV ONLY\n",
    "print(len(cites))\n",
    "print(len(pmc_rows))\n",
    "print(len(status_pmc))\n",
    "print(scrape_more)\n",
    "##!!!!!!!!! DEV ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### PMC Section\n",
    "\n",
    "#####  For updated PMC interface\n",
    "# log into era commons\n",
    "attempt = 1\n",
    "while attempt <= 3:\n",
    "    try:\n",
    "        driver = pub_comp_lib.ncbi_login(config.ncbi_login, config.ncbi_pass)\n",
    "        attempt = 4\n",
    "    except Exception as err:\n",
    "        logger.warning('Unable to log into ERA Commons, attempt %i; error: %s' % (attempt, str(err)))\n",
    "        attempt += 1\n",
    "        time.sleep(2)\n",
    "\n",
    "# get list of publications with during current grant cycle with no pmcid to check on\n",
    "# nihms status\n",
    "pubs_frame['pub_date'] = pd.to_datetime(pubs_frame['pub_date'], format='%Y-%m-%d')\n",
    "#config.start = datetime.strptime(config.start, '%m/%d/%Y')\n",
    "\n",
    "#!!!!!!! how much of the pubmed results are going to pmc to check for compliance\n",
    "#status_pmc = pubs_frame.pmid[(pubs_frame.pub_date > config.start) & (pubs_frame.pmc_id.isnull())]\n",
    "#status_pmc = pubs_frame.pmid[pubs_frame.pmc_id.isnull()]\n",
    "#status_pmc = pubs_frame.pmid[(pubs_frame.pub_date > config.start)]\n",
    "status_pmc = pubs_frame.pmid\n",
    "\n",
    "##!!!!!!!!! DEV ONLY csv file since I can't tell if all pmids are being sent to pmc\n",
    "status_pmc.to_csv('pmids_to_check_in_pmc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 0 : 200 and rows-0    minutes-1004.2\n",
      "Working on 200 : 400 and rows-0    minutes-1009.9\n",
      "May need to wait longer for awards to load, got 0 for pmid: 31910032\n",
      "May need to wait longer for awards to load, got 0 for pmid: 31942683\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30610655\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30509852\n",
      "May need to wait longer for awards to load, got 0 for pmid: 31446976\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30635978\n",
      "May need to wait longer for awards to load, got 0 for pmid: 31258977\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30946739\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30367828\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30686507\n",
      "Well maybe there are no awards for pmid: 30686507\n",
      "Might have failed on -cancel association- button for pmid: 30686507\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30679213\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30522545\n",
      "Well maybe there are no awards for pmid: 30522545\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30395503\n",
      "May need to wait longer for awards to load, got 0 for pmid: 30281148\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29734508\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29950384\n",
      "Well maybe there are no awards for pmid: 29950384\n",
      "Might have failed on -cancel association- button for pmid: 29950384\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29520864\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29651255\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29540160\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29129582\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29053189\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29392683\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29391657\n",
      "May need to wait longer for awards to load, got 0 for pmid: 28961980\n",
      "May need to wait longer for awards to load, got 0 for pmid: 29664482\n",
      "May need to wait longer for awards to load, got 0 for pmid: 28481195\n",
      "May need to wait longer for awards to load, got 0 for pmid: 28143694\n",
      "May need to wait longer for awards to load, got 0 for pmid: 28129517\n",
      "May need to wait longer for awards to load, got 0 for pmid: 27743228\n",
      "May need to wait longer for awards to load, got 0 for pmid: 31474786\n",
      "May need to wait longer for awards to load, got 0 for pmid: 28212287\n",
      "May need to wait longer for awards to load, got 0 for pmid: 27570892\n",
      "Well maybe there are no awards for pmid: 27570892\n",
      "May need to wait longer for awards to load, got 0 for pmid: 27830114\n",
      "May need to wait longer for awards to load, got 0 for pmid: 27545880\n",
      "May need to wait longer for awards to load, got 0 for pmid: 26508715\n",
      "May need to wait longer for awards to load, got 0 for pmid: 27812274\n",
      "May need to wait longer for awards to load, got 0 for pmid: 27026198\n",
      "May need to wait longer for awards to load, got 0 for pmid: 26777286\n",
      "May need to wait longer for awards to load, got 0 for pmid: 27148013\n",
      "May need to wait longer for awards to load, got 0 for pmid: 26912863\n",
      "May need to wait longer for awards to load, got 0 for pmid: 26631723\n",
      "May need to wait longer for awards to load, got 0 for pmid: 26280354\n",
      "May need to wait longer for awards to load, got 0 for pmid: 26776191\n",
      "May need to wait longer for awards to load, got 0 for pmid: 26350957\n",
      "May need to wait longer for awards to load, got 0 for pmid: 26413716\n",
      "Well maybe there are no awards for pmid: 26413716\n",
      "Might have failed on -cancel association- button for pmid: 26413716\n",
      "May need to wait longer for awards to load, got 0 for pmid: 23489774\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25586885\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25965353\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25266681\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25728149\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25592437\n",
      "Well maybe there are no awards for pmid: 25592437\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25585327\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25313992\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25261342\n",
      "Well maybe there are no awards for pmid: 25261342\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25337600\n",
      "Well maybe there are no awards for pmid: 25337600\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25274799\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25250047\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24453089\n",
      "Well maybe there are no awards for pmid: 24453089\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24330310\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25009491\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24882899\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24006239\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24754822\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24670687\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24576767\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24622158\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24114402\n",
      "May need to wait longer for awards to load, got 0 for pmid: 23917470\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24533002\n",
      "May need to wait longer for awards to load, got 0 for pmid: 25207618\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24933724\n",
      "Well maybe there are no awards for pmid: 24933724\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24290281\n",
      "May need to wait longer for awards to load, got 0 for pmid: 24150468\n",
      "May need to wait longer for awards to load, got 0 for pmid: 23597935\n",
      "May need to wait longer for awards to load, got 0 for pmid: 23403405\n",
      "May need to wait longer for awards to load, got 0 for pmid: 23298435\n",
      "Well maybe there are no awards for pmid: 23298435\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22936805\n",
      "May need to wait longer for awards to load, got 0 for pmid: 23087635\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22743305\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22683399\n",
      "Well maybe there are no awards for pmid: 22683399\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22647787\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22937210\n",
      "Well maybe there are no awards for pmid: 22937210\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22653256\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22701578\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22606276\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22541416\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22290875\n",
      "Well maybe there are no awards for pmid: 22290875\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22186938\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22317309\n",
      "May need to wait longer for awards to load, got 0 for pmid: 22093452\n",
      "May need to wait longer for awards to load, got 0 for pmid: 21788561\n",
      "May need to wait longer for awards to load, got 0 for pmid: 21094927\n",
      "May need to wait longer for awards to load, got 0 for pmid: 21838686\n",
      "May need to wait longer for awards to load, got 0 for pmid: 20551942\n",
      "May need to wait longer for awards to load, got 0 for pmid: 20497112\n",
      "May need to wait longer for awards to load, got 0 for pmid: 20603056\n",
      "May need to wait longer for awards to load, got 0 for pmid: 20391535\n",
      "May need to wait longer for awards to load, got 0 for pmid: 19362885\n",
      "May need to wait longer for awards to load, got 0 for pmid: 19076668\n",
      "Well maybe there are no awards for pmid: 19076668\n",
      "Working on 400 : 600 and rows-200    minutes-1047.8\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'search_field' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e0e14bfb61af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.ncbi.nlm.nih.gov/myncbi/collections/mybibliography/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpub_comp_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_my_bib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpub_comp_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_my_bib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus_pmc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# reload my bib and begin scraping each page of citations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Coding/pub_compliance/pub_comp_lib.py\u001b[0m in \u001b[0;36madd_to_my_bib\u001b[0;34m(driver, add_pubs, delay, long_delay, logger)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mattempt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0msearch_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_pubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//*[@id=\"search-but\"]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'search_field' referenced before assignment"
     ]
    }
   ],
   "source": [
    "####################### scrape pmc information in batches\n",
    "pmc_rows = []\n",
    "batch_size = 200\n",
    "count = len(status_pmc)\n",
    "delay = 2\n",
    "long_delay = 7\n",
    "\n",
    "for start in range(0, count, batch_size):\n",
    "    end = min(count, start+batch_size)\n",
    "    # reload my bib, clear all publications and load pmids in status_pmc\n",
    "    driver.get('https://www.ncbi.nlm.nih.gov/myncbi/collections/mybibliography/')\n",
    "    pub_comp_lib.clear_my_bib(driver, delay, logger)\n",
    "    pub_comp_lib.add_to_my_bib(driver, status_pmc[start:end], delay, long_delay, logger)\n",
    "    # reload my bib and begin scraping each page of citations\n",
    "    time.sleep(delay)\n",
    "    driver.get('https://www.ncbi.nlm.nih.gov/myncbi/collections/mybibliography/')\n",
    "    time.sleep(delay)\n",
    "    scrape_more = 1\n",
    "    #### loop for each 'next page' click\n",
    "    while scrape_more == 1:\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        cites = soup.find_all('div', 'citation-wrap')\n",
    "        for x in range(len(cites)):\n",
    "            pmc_rows.append(pub_comp_lib.scrape_citations(cites[x], x, variations, driver, delay, long_delay, logger, start))\n",
    "        ## check if there's another page of citations to scrape\n",
    "        time.sleep(delay)\n",
    "        try:\n",
    "            next_button = driver.find_element_by_xpath('//*[@id=\"pager1\"]/ul/li[4]/a').get_attribute('onclick')\n",
    "        except Exception as err:\n",
    "            next_button = 'return false;'\n",
    "        if next_button == 'return false;' or driver.find_element_by_xpath('//*[@id=\"pager2\"]/ul/li/span').get_attribute('innerText') == '1':\n",
    "            scrape_more = 0\n",
    "        else: driver.find_element_by_xpath('//*[@id=\"pager1\"]/ul/li[4]/a').click()\n",
    "    if count > 1000:\n",
    "        time.sleep(90)\n",
    "        print('Working on ' + str(start) + ' : ' + str(end) + ' and rows-' + str(len(pmc_rows)) + '    minutes-{0:0.1f}' .format((time.time()-start_time)/60))\n",
    "driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n",
      "2864\n",
      "2800\n",
      "2864\n"
     ]
    }
   ],
   "source": [
    "##########!!!!!!***** Dev interrupt and jump off point\n",
    "print(len(pmc_rows))\n",
    "print(len(status_pmc))\n",
    "print(start)\n",
    "print(end)\n",
    "\n",
    "##########!!!!!!*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## package the pmc_rows into a data frame\n",
    "pmc_frame = pd.DataFrame(pmc_rows, columns=['pmid', 'pmc_status', 'pmc_tags', 'all_awards', 'pub_num'])\n",
    "pmc_frame.to_csv('DEV_batch_pmc_status.csv', index=False)\n",
    "# change blank values to nan- makes column merging easier\n",
    "pmc_frame[pmc_frame == ''] = np.nan\n",
    "\n",
    "# drop the pub_num column after the data frame has been written to csv file\n",
    "pmc_frame = pmc_frame.drop('pub_num', 1)\n",
    "\n",
    "# get list of publications with non-compliant pmc status to check on\n",
    "# nihms status\n",
    "status_nihms = pmc_frame.pmid[pmc_frame['pmc_status'].isin(['2', '3', '4', ''])]\n",
    "###################### END PMC Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# NEW NIHMS Section\n",
    "\n",
    "nihms_frame = pub_comp_lib.get_nihms(status_nihms, config.ncbi_login, config.ncbi_pass, 1, 5)\n",
    "\n",
    "nihms_frame.to_csv('DEV_batch_nihms_status.csv', index=False)\n",
    "# change blank values to nan- makes column merging easier\n",
    "nihms_frame[pmc_frame == ''] = np.nan\n",
    "\n",
    "################# END NEW NIHMS Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## join pmids, pmc, and nihms tables and upload into REDCap\n",
    "pub_comp = pd.merge(pubs_frame, pmc_frame, on='pmid', how='outer')\n",
    "pub_comp = pd.merge(pub_comp, nihms_frame, on='pmid', how='outer')\n",
    "\n",
    "\n",
    "# include nihms ids from all dataframes into a final column\n",
    "pub_comp['nihms_id'] = pub_comp['nihms_id_x'].combine_first(pub_comp['nihms_id_y'])\n",
    "pub_comp['nihms_id'] = pub_comp['nihms_id_y'].combine_first(pub_comp['nihms_id'])\n",
    "\n",
    "# include pmc ids from all dataframes into a final column\n",
    "pub_comp['pmc_id'] = pub_comp['pmc_id_x'].combine_first(pub_comp['pmc_id_y'])\n",
    "pub_comp['pmc_id'] = pub_comp['pmc_id_y'].combine_first(pub_comp['pmc_id'])\n",
    "\n",
    "# include pmc status from all dataframes into a final column\n",
    "pub_comp['pmc_status'] = pub_comp['pmc_status_x'].combine_first(pub_comp['pmc_status_y'])\n",
    "pub_comp['pmc_status'] = pub_comp['pmc_status_y'].combine_first(pub_comp['pmc_status'])\n",
    "\n",
    "# remove columns now that pmc and nihms ids have been merged\n",
    "pub_comp = pub_comp.drop(['nihms_id_x', 'nihms_id_y'], axis=1)\n",
    "pub_comp = pub_comp.drop(['pmc_id_x', 'pmc_id_y'], axis=1)\n",
    "pub_comp = pub_comp.drop(['pmc_status_x', 'pmc_status_y'], axis=1)\n",
    "\n",
    "pub_comp['nihms_comm'] = ''\n",
    "\n",
    "### Update REDCap project if one is being used to track publications\n",
    "if config.rc_token is not None and config.rc_uri is not None and len(pmids) < 5000:\n",
    "    pub_comp = pub_comp_lib.RC_update_status(pub_comp)\n",
    "    success = project.import_records(pub_comp)\n",
    "\n",
    "# write a copy to a .csv file\n",
    "pub_comp.to_csv('batch_comprehensive_status.csv', index=False)\n",
    "\n",
    "print('Publication compliance status update process complete in {0:0.1f} minutes' .format((time.time()-start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status_pmc = ['31443893', '31280053', '30968993', '31568479', '31390231', '31161938']\n",
    "delay = 2\n",
    "long_delay = 7\n",
    "pmc_rows = []\n",
    "start = 0\n",
    "count = len(status_pmc)\n",
    "scrape_more = 1\n",
    "end = 50\n",
    "####################### Development section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got 50\n"
     ]
    }
   ],
   "source": [
    "print('I got ' + str(end+start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "status_pmc = ['31443893', '31280053', '30968993', '31568479', '31390231', '31161938', '31443893', '31280053', '30968993', '31568479', '31390231', '31161938']\n",
    "batch_size = 5\n",
    "lap = 1\n",
    "count = len(status_pmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lap= 1\n",
      "Start= 0\n",
      "Count= 12\n",
      "Lap= 2\n",
      "Start= 5\n",
      "Count= 12\n",
      "Lap= 3\n",
      "Start= 10\n",
      "Count= 12\n"
     ]
    }
   ],
   "source": [
    "for start in range(0, count, batch_size):\n",
    "    end = min(count, start+batch_size)\n",
    "    print(\"Lap= \"+str(lap))\n",
    "    print(\"Start= \"+str(start))\n",
    "    print(\"Count= \"+str(count))\n",
    "    lap += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
