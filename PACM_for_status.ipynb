{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from Bio import Entrez\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from redcap import Project\n",
    "from datetime import datetime\n",
    "\n",
    "### Get access keys from the setup file - config.py\n",
    "import config\n",
    "import pub_comp_lib\n",
    "\n",
    "# ## !!** For DEV\n",
    "from importlib import reload\n",
    "# reload(name_of_module)\n",
    "# ## !!** For DEV\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"test.log\", \n",
    "    level=logging.DEBUG, \n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "#logger = logging.basicConfig(filename='app.log', filemode='w',\n",
    "#                             format='%(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# loop over all config grants for cleanup\n",
    "for x in range(len(config.grant_list)):\n",
    "    # remove all whitespace, leading or trailing hyphenates - clean_grant.py\n",
    "    config.grant_list[x] = pub_comp_lib.clean(config.grant_list[x])\n",
    "\n",
    "### Create list for each grant with 34 grant variations - grant_vari.py\n",
    "variations = []\n",
    "for grant in config.grant_list:\n",
    "    variations.extend(pub_comp_lib.variety(grant))\n",
    "\n",
    "### Get pmids from pubmed for all grant variations\n",
    "# create variables for pubmed queries\n",
    "Entrez.email = \"Your.Name.Here@example.org\"\n",
    "Entrez.api_key = config.ncbi_api\n",
    "\n",
    "# create set for unique list of all pmids from querying pubmed with each\n",
    "# grant variation\n",
    "pmids = set()\n",
    "# query pubmed for pmids associated with each grant variation\n",
    "logger.info(\"Starting pubmed queries...\")\n",
    "pubmed_results = []\n",
    "\n",
    "for grant in variations:\n",
    "    attempt = 1\n",
    "    while attempt <= 3:\n",
    "        try:\n",
    "            handle = Entrez.esearch(db='pubmed', term=grant,\n",
    "                                    field='grant', retmax=5000,\n",
    "                                    usehistory='y', retmode='xml')\n",
    "            record = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            if int(record['Count']) > 0:\n",
    "                pubmed_results.append(record)\n",
    "                pmids.update(record['IdList'])\n",
    "                logger.info('Entrez ESearch returns %i Ids for %s' % (int(record['Count']), str(grant)))\n",
    "            attempt = 4\n",
    "        except Exception as err:\n",
    "            logger.warning('Received error from server: %s' % str(err))\n",
    "            logger.warning('Attempt %i of 3 for grant %s.' % (attempt,\n",
    "                                                              str(grant)))\n",
    "            attempt += 1\n",
    "            time.sleep(2)\n",
    "    logger.debug('Grant %s queried.' % str(grant))\n",
    "\n",
    "logger.info('All grant queries complete.')\n",
    "\n",
    "### Update pmid set if a REDCap project is being used to track publications\n",
    "if config.rc_token is not None and config.rc_uri is not None:\n",
    "    old_pmids = []\n",
    "    # get the full pmid list from the REDCap project\n",
    "    project = Project(config.rc_uri, config.rc_token)\n",
    "    rc_pmids = project.export_records(fields=['pmid'], format='json')\n",
    "    for rc_pmid in rc_pmids:\n",
    "        old_pmids.append(rc_pmid['pmid'])\n",
    "    new_pmids = list(pmids.difference(old_pmids))   # newly discovered pmids\n",
    "    pmids.update(old_pmids)\n",
    "    # date of first discovery\n",
    "    if len(new_pmids) > 0:\n",
    "        first_disc = [datetime.today().strftime(\"%Y-%m-%d\")]*len(new_pmids)\n",
    "        # create data frame of new_pmids with date of first dicovery and\n",
    "        # import into REDCap project\n",
    "        # create data frame using lists and import into redcap\n",
    "        first_discovered_frame = pd.DataFrame(np.column_stack([new_pmids, first_disc]),\n",
    "                            columns=['pmid', 'first_discovered'])\n",
    "        response = project.import_records(first_discovered_frame)\n",
    "\n",
    "### Get table of publication details from pubmed for pmids\n",
    "# make dataframe of publications\n",
    "pubs_frame = pub_comp_lib.summary(pmids, config.ncbi_api, variations)\n",
    "# add compliant pmc status for publications with a pmcid\n",
    "pubs_frame['pmc_status'] = np.where(pubs_frame.pmcid == '', '', '1')\n",
    "# write table\n",
    "pubs_frame.to_csv('batch_pubmed_frame.csv', index=False)\n",
    "\n",
    "# change blank values to nan- makes column merging easier\n",
    "pubs_frame[pubs_frame == ''] = np.nan\n",
    "\n",
    "\n",
    "###################### PMC Section\n",
    "\n",
    "# loop batches of ~50 pmids for pmc status and tags check\n",
    "#pmc_rows = pmc_status.pmc_scrape(pubs_frame.pmid[0:50], variations, config.ncbi_login, config.ncbi_pass)\n",
    "#pmc_rows = []\n",
    "#batch = 50\n",
    "#for x in range(0, len(pubs_frame.pmid[0:101]), batch):\n",
    "#    pmc_rows.extend(pmc_status.pmc_scrape(pubs_frame.pmid[x:x+batch], variations, config.ncbi_login, config.ncbi_pass))\n",
    "\n",
    "#pmc_frame = pd.DataFrame(pmc_rows, columns=['pmid', 'pmc_status', 'pmc_tags', 'all_awards'])\n",
    "#pmc_frame.to_csv('DEV_batch_pmc_status.csv', index=False)\n",
    "# change blank values to nan- makes column merging easier\n",
    "#pmc_frame[pmc_frame == ''] = np.nan\n",
    "\n",
    "# get list of publications with red/grey/yellow pmc status to check on\n",
    "# nihms status\n",
    "#check_status = pmc_frame.pmid[pmc_frame['pmc_status'].isin(['2', '3', '4'])]\n",
    "\n",
    "###################### END PMC Section\n",
    "\n",
    "###################### Start NIHMS Section\n",
    "# get list of publications with during current grant cycle with no pmcid to check on\n",
    "# nihms status\n",
    "#pubs_frame['pub_date'] = pd.to_datetime(pubs_frame['pub_date'], format='%Y-%m-%d')\n",
    "#config.start = datetime.strptime(config.start, '%m/%d/%Y')\n",
    "#check_status = pubs_frame.pmid[(pubs_frame.pub_date > config.start) & (pubs_frame.pmcid.isnull())]\n",
    "\n",
    "\n",
    "### Check NIHMS status\n",
    "#nihms_frame = pub_comp_lib.get_nihms(check_status, config.ncbi_login, config.ncbi_pass)\n",
    "#nihms_frame.to_csv('batch_nihms_status.csv', index=False)\n",
    "\n",
    "# change blank values to nan- makes column merging easier\n",
    "#nihms_frame[nihms_frame == ''] = np.nan\n",
    "\n",
    "### Merge the dataframes for final report\n",
    "#pub_comp = pd.merge(pubs_frame, pmc_frame, on='pmid', how='outer').merge(nihms_frame, on='pmid', how='outer')\n",
    "#pub_comp = pd.merge(pubs_frame, nihms_frame, on='pmid', how='outer')\n",
    "\n",
    "\n",
    "# include nihms ids from all dataframes into a final column\n",
    "#pub_comp['nihms_id'] = pub_comp['nihmsid_x'].combine_first(pub_comp['nihmsid_y'])\n",
    "#pub_comp['nihms_id'] = pub_comp['nihmsid_y'].combine_first(pub_comp['nihms_id'])\n",
    "\n",
    "# include pmc ids from all dataframes into a final column\n",
    "#pub_comp['pmc_id'] = pub_comp['pmcid_x'].combine_first(pub_comp['pmcid_y'])\n",
    "#pub_comp['pmc_id'] = pub_comp['pmcid_y'].combine_first(pub_comp['pmc_id'])\n",
    "\n",
    "# remove columns now that pmc and nihms ids have been merged\n",
    "#pub_comp = pub_comp.drop(['nihmsid_x', 'nihmsid_y','pmcid_x', 'pmcid_y'], axis=1)\n",
    "###################### END NIHMS Section\n",
    "\n",
    "###################### PACM Public Access Compliance Monitor for NIHMS status\n",
    "# establish the root of the pacm publication url\n",
    "pacm_root = 'https://www.ncbi.nlm.nih.gov/pmc/utils/pacm/l/'\n",
    "\n",
    "if config.pacm == 'y':\n",
    "    driver = pub_comp_lib.pacm_login(config.era_login, config.era_pass)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # get list of publications with during current grant cycle with no pmcid to check on\n",
    "    # nihms status\n",
    "    pubs_frame['pub_date'] = pd.to_datetime(pubs_frame['pub_date'], format='%Y-%m-%d')\n",
    "    #config.start = datetime.strptime(config.start, '%m/%d/%Y')\n",
    "    check_status = pubs_frame.pmid[(pubs_frame.pub_date > config.start) & (pubs_frame.pmcid.isnull())]\n",
    "    \n",
    "    pacm_rows = [pub_comp_lib.parse_pacm(driver, pacm_root, x, variations) for x in check_status]\n",
    "    pacm_frame = pd.DataFrame(pacm_rows, columns=['pmid', 'nihms_id', 'nihms_status', \n",
    "                                                  'journal_method', 'files_deposited', \n",
    "                                                  'initial_approval', 'tagging_complete', \n",
    "                                                  'final_approval', 'initial_actor', \n",
    "                                                  'latest_actor', 'pacm_grants'])\n",
    "    driver.quit()\n",
    "###################### END PACM Section\n",
    "\n",
    "pub_comp = pubs_frame.rename(columns={'pmcid':'pmc_id', 'nihmsid': 'nihms_id'})\n",
    "\n",
    "pub_comp = pd.merge(pub_comp, pacm_frame, on='pmid', how='outer')\n",
    "# include nihms ids from all dataframes into a final column\n",
    "pub_comp['nihms_id'] = pub_comp['nihms_id_x'].combine_first(pub_comp['nihms_id_y'])\n",
    "pub_comp['nihms_id'] = pub_comp['nihms_id_y'].combine_first(pub_comp['nihms_id'])\n",
    "# remove columns now that pmc and nihms ids have been merged\n",
    "pub_comp = pub_comp.drop(['nihms_id_x', 'nihms_id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pub_comp_lib.py libraries\n",
    "from Bio import Entrez\n",
    "from Bio.Entrez import efetch\n",
    "from Bio.Entrez import read\n",
    "import regex as re\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_comp.loc[pub_comp['pmc_id'].isnull() == False, 'nihms_comm'] = '5'\n",
    "pub_comp.loc[pub_comp['nihms_status'] == 'Compliant', 'nihms_comm'] = '5'\n",
    "pub_comp.loc[pub_comp['nihms_status'] == 'Excluded', 'nihms_comm'] = '6'\n",
    "pub_comp.loc[pub_comp['nihms_status'] == 'Excluded', 'author_excluded'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pub_comp.loc[pub_comp['tagging_complete'] == '', 'nihms_comm'] = '4'\n",
    "pub_comp.loc[pub_comp['final_approval'] == '', 'nihms_comm'] = '3'\n",
    "pub_comp.loc[pub_comp['initial_approval'] == '', 'nihms_comm'] = '2'\n",
    "pub_comp.loc[pub_comp['files_deposited'] == '', 'nihms_comm'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_comp['journal_method'] = pub_comp['journal_method'].fillna('')\n",
    "pub_comp.journal_method = pub_comp.journal_method.apply(lambda x: '0' if 'No' in x else x)\n",
    "pub_comp.journal_method = pub_comp.journal_method.apply(lambda x: '1' if 'Yes' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_comp['files_deposited'] = pub_comp['files_deposited'].fillna('')\n",
    "pub_comp.files_deposited = pub_comp.files_deposited.apply(lambda x: x if x in '' else datetime.datetime.strptime(x, \"%m/%d/%y\").strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pub_comp['files_deposited'] = pub_comp['files_deposited'].fillna('')\n",
    "pub_comp.files_deposited = pub_comp.files_deposited.apply(lambda x: x if x in '' else datetime.datetime.strptime(x, \"%m/%d/%y\").strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_comp.to_csv('batch_comprehensive_status.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82      2019-10-15\n",
       "151     2020-02-21\n",
       "192     2019-11-25\n",
       "631     2020-02-12\n",
       "811     2020-02-14\n",
       "898     2019-07-16\n",
       "934     2020-02-12\n",
       "1043    2020-02-12\n",
       "1113    2020-02-18\n",
       "1224    2019-12-26\n",
       "1233    2019-12-15\n",
       "1466    2020-02-13\n",
       "1554    2019-07-31\n",
       "1638    2019-11-25\n",
       "1649    2020-01-10\n",
       "1983    2018-09-24\n",
       "2022    2020-01-15\n",
       "2200    2019-09-25\n",
       "2487    2020-02-06\n",
       "2660    2019-11-25\n",
       "Name: files_deposited, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_comp.loc[pub_comp['files_deposited'] != '', 'files_deposited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
