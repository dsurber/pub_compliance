{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from Bio import Entrez\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from redcap import Project\n",
    "from datetime import datetime\n",
    "\n",
    "### Get access keys from the setup file - config.py\n",
    "import config\n",
    "import pub_comp_lib\n",
    "\n",
    "# ## !!** For DEV\n",
    "from importlib import reload\n",
    "# reload(name_of_module)\n",
    "# ## !!** For DEV\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"test.log\", \n",
    "    level=logging.DEBUG, \n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "#logger = logging.basicConfig(filename='app.log', filemode='w',\n",
    "#                             format='%(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# loop over all config grants for cleanup\n",
    "for x in range(len(config.grant_list)):\n",
    "    # remove all whitespace, leading or trailing hyphenates - clean_grant.py\n",
    "    config.grant_list[x] = pub_comp_lib.clean(config.grant_list[x])\n",
    "\n",
    "### Create list for each grant with 34 grant variations - grant_vari.py\n",
    "variations = []\n",
    "for grant in config.grant_list:\n",
    "    variations.extend(pub_comp_lib.variety(grant))\n",
    "\n",
    "### Get pmids from pubmed for all grant variations\n",
    "# create variables for pubmed queries\n",
    "Entrez.email = \"Your.Name.Here@example.org\"\n",
    "Entrez.api_key = config.ncbi_api\n",
    "\n",
    "# create set for unique list of all pmids from querying pubmed with each\n",
    "# grant variation\n",
    "pmids = set()\n",
    "# query pubmed for pmids associated with each grant variation\n",
    "logger.info(\"Starting pubmed queries...\")\n",
    "pubmed_results = []\n",
    "\n",
    "for grant in variations:\n",
    "    attempt = 1\n",
    "    while attempt <= 3:\n",
    "        try:\n",
    "            handle = Entrez.esearch(db='pubmed', term=grant,\n",
    "                                    field='grant', retmax=5000,\n",
    "                                    usehistory='y', retmode='xml')\n",
    "            record = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            if int(record['Count']) > 0:\n",
    "                pubmed_results.append(record)\n",
    "                pmids.update(record['IdList'])\n",
    "                logger.info('Entrez ESearch returns %i Ids for %s' % (int(record['Count']), str(grant)))\n",
    "            attempt = 4\n",
    "        except Exception as err:\n",
    "            logger.warning('Received error from server: %s' % str(err))\n",
    "            logger.warning('Attempt %i of 3 for grant %s.' % (attempt,\n",
    "                                                              str(grant)))\n",
    "            attempt += 1\n",
    "            time.sleep(2)\n",
    "    logger.debug('Grant %s queried.' % str(grant))\n",
    "\n",
    "logger.info('All grant queries complete.')\n",
    "\n",
    "### Update pmid set if a REDCap project is being used to track publications\n",
    "if config.rc_token is not None and config.rc_uri is not None:\n",
    "    old_pmids = []\n",
    "    # get the full pmid list from the REDCap project\n",
    "    project = Project(config.rc_uri, config.rc_token)\n",
    "    rc_pmids = project.export_records(fields=['pmid'], format='json')\n",
    "    for rc_pmid in rc_pmids:\n",
    "        old_pmids.append(rc_pmid['pmid'])\n",
    "    new_pmids = list(pmids.difference(old_pmids))   # newly discovered pmids\n",
    "    pmids.update(old_pmids)\n",
    "    # date of first discovery\n",
    "    if len(new_pmids) > 0:\n",
    "        first_disc = [datetime.today().strftime(\"%Y-%m-%d\")]*len(new_pmids)\n",
    "        # create data frame of new_pmids with date of first dicovery and\n",
    "        # import into REDCap project\n",
    "        # create data frame using lists and import into redcap\n",
    "        first_discovered_frame = pd.DataFrame(np.column_stack([new_pmids, first_disc]),\n",
    "                            columns=['pmid', 'first_discovered'])\n",
    "        response = project.import_records(first_discovered_frame)\n",
    "\n",
    "### Get table of publication details from pubmed for pmids\n",
    "# make dataframe of publications\n",
    "pubs_frame = pub_comp_lib.summary(pmids, config.ncbi_api, variations)\n",
    "# add compliant pmc status for publications with a pmcid\n",
    "pubs_frame['pmc_status'] = np.where(pubs_frame.pmcid == '', '', '1')\n",
    "# write table\n",
    "pubs_frame.to_csv('batch_pubmed_frame.csv', index=False)\n",
    "\n",
    "# change blank values to nan- makes column merging easier\n",
    "pubs_frame[pubs_frame == ''] = np.nan\n",
    "\n",
    "\n",
    "###################### PMC Section\n",
    "\n",
    "# loop batches of ~50 pmids for pmc status and tags check\n",
    "#pmc_rows = pmc_status.pmc_scrape(pubs_frame.pmid[0:50], variations, config.ncbi_login, config.ncbi_pass)\n",
    "#pmc_rows = []\n",
    "#batch = 50\n",
    "#for x in range(0, len(pubs_frame.pmid[0:101]), batch):\n",
    "#    pmc_rows.extend(pmc_status.pmc_scrape(pubs_frame.pmid[x:x+batch], variations, config.ncbi_login, config.ncbi_pass))\n",
    "\n",
    "#pmc_frame = pd.DataFrame(pmc_rows, columns=['pmid', 'pmc_status', 'pmc_tags', 'all_awards'])\n",
    "#pmc_frame.to_csv('DEV_batch_pmc_status.csv', index=False)\n",
    "# change blank values to nan- makes column merging easier\n",
    "#pmc_frame[pmc_frame == ''] = np.nan\n",
    "\n",
    "# get list of publications with red/grey/yellow pmc status to check on\n",
    "# nihms status\n",
    "#check_status = pmc_frame.pmid[pmc_frame['pmc_status'].isin(['2', '3', '4'])]\n",
    "\n",
    "###################### END PMC Section\n",
    "\n",
    "###################### Start NIHMS Section\n",
    "# get list of publications with during current grant cycle with no pmcid to check on\n",
    "# nihms status\n",
    "#pubs_frame['pub_date'] = pd.to_datetime(pubs_frame['pub_date'], format='%Y-%m-%d')\n",
    "#config.start = datetime.strptime(config.start, '%m/%d/%Y')\n",
    "#check_status = pubs_frame.pmid[(pubs_frame.pub_date > config.start) & (pubs_frame.pmcid.isnull())]\n",
    "\n",
    "\n",
    "### Check NIHMS status\n",
    "#nihms_frame = pub_comp_lib.get_nihms(check_status, config.ncbi_login, config.ncbi_pass)\n",
    "#nihms_frame.to_csv('batch_nihms_status.csv', index=False)\n",
    "\n",
    "# change blank values to nan- makes column merging easier\n",
    "#nihms_frame[nihms_frame == ''] = np.nan\n",
    "\n",
    "### Merge the dataframes for final report\n",
    "#pub_comp = pd.merge(pubs_frame, pmc_frame, on='pmid', how='outer').merge(nihms_frame, on='pmid', how='outer')\n",
    "#pub_comp = pd.merge(pubs_frame, nihms_frame, on='pmid', how='outer')\n",
    "\n",
    "\n",
    "# include nihms ids from all dataframes into a final column\n",
    "#pub_comp['nihms_id'] = pub_comp['nihmsid_x'].combine_first(pub_comp['nihmsid_y'])\n",
    "#pub_comp['nihms_id'] = pub_comp['nihmsid_y'].combine_first(pub_comp['nihms_id'])\n",
    "\n",
    "# include pmc ids from all dataframes into a final column\n",
    "#pub_comp['pmc_id'] = pub_comp['pmcid_x'].combine_first(pub_comp['pmcid_y'])\n",
    "#pub_comp['pmc_id'] = pub_comp['pmcid_y'].combine_first(pub_comp['pmc_id'])\n",
    "\n",
    "# remove columns now that pmc and nihms ids have been merged\n",
    "#pub_comp = pub_comp.drop(['nihmsid_x', 'nihmsid_y','pmcid_x', 'pmcid_y'], axis=1)\n",
    "###################### END NIHMS Section\n",
    "\n",
    "###################### PACM Public Access Compliance Monitor for NIHMS status\n",
    "# establish the root of the pacm publication url\n",
    "pacm_root = 'https://www.ncbi.nlm.nih.gov/pmc/utils/pacm/l/'\n",
    "\n",
    "if config.pacm == 'y':\n",
    "    driver = pub_comp_lib.pacm_login(config.era_login, config.era_pass)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # get list of publications with during current grant cycle with no pmcid to check on\n",
    "    # nihms status\n",
    "    pubs_frame['pub_date'] = pd.to_datetime(pubs_frame['pub_date'], format='%Y-%m-%d')\n",
    "    #config.start = datetime.strptime(config.start, '%m/%d/%Y')\n",
    "    check_status = pubs_frame.pmid[(pubs_frame.pub_date > config.start) & (pubs_frame.pmcid.isnull())]\n",
    "    \n",
    "    pacm_rows = [pub_comp_lib.parse_pacm(driver, pacm_root, x, variations) for x in check_status]\n",
    "    pacm_frame = pd.DataFrame(pacm_rows, columns=['pmid', 'nihms_id', 'nihms_status', \n",
    "                                                  'journal_method', 'files_deposited', \n",
    "                                                  'initial_approval', 'tagging_complete', \n",
    "                                                  'final_approval', 'initial_actor', \n",
    "                                                  'latest_actor', 'pacm_grants'])\n",
    "    driver.quit()\n",
    "###################### END PACM Section\n",
    "\n",
    "pub_comp = pubs_frame.rename(columns={'pmcid':'pmc_id', 'nihmsid': 'nihms_id'})\n",
    "\n",
    "pub_comp = pd.merge(pub_comp, pacm_frame, on='pmid', how='outer')\n",
    "# include nihms ids from all dataframes into a final column\n",
    "pub_comp['nihms_id'] = pub_comp['nihms_id_x'].combine_first(pub_comp['nihms_id_y'])\n",
    "pub_comp['nihms_id'] = pub_comp['nihms_id_y'].combine_first(pub_comp['nihms_id'])\n",
    "# remove columns now that pmc and nihms ids have been merged\n",
    "pub_comp = pub_comp.drop(['nihms_id_x', 'nihms_id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pub_comp_lib.py libraries\n",
    "from Bio import Entrez\n",
    "from Bio.Entrez import efetch\n",
    "from Bio.Entrez import read\n",
    "import regex as re\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_comp.loc[pub_comp['pmc_id'].isnull() == False, 'nihms_comm'] = '5'\n",
    "pub_comp.loc[pub_comp['nihms_status'] == 'Compliant', 'nihms_comm'] = '5'\n",
    "pub_comp.loc[pub_comp['nihms_status'] == 'Excluded', 'nihms_comm'] = '6'\n",
    "pub_comp.loc[pub_comp['nihms_status'] == 'Excluded', 'author_excluded'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_comp.loc[pub_comp['tagging_complete'] == '', 'nihms_comm'] = '4'\n",
    "pub_comp.loc[pub_comp['final_approval'] == '', 'nihms_comm'] = '3'\n",
    "pub_comp.loc[pub_comp['initial_approval'] == '', 'nihms_comm'] = '2'\n",
    "pub_comp.loc[pub_comp['files_deposited'] == '', 'nihms_comm'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_comp['journal_method'] = pub_comp['journal_method'].fillna('')\n",
    "pub_comp.journal_method = pub_comp.journal_method.apply(lambda x: '0' if 'No' in x else x)\n",
    "pub_comp.journal_method = pub_comp.journal_method.apply(lambda x: '1' if 'Yes' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_comp['files_deposited'] = pub_comp['files_deposited'].fillna('')\n",
    "pub_comp.files_deposited = pub_comp.files_deposited.apply(lambda x: x if x in '' else datetime.datetime.strptime(x, \"%m/%d/%y\").strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '2020-01-10' does not match format '%m/%d/%y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf6ba8e637d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpub_comp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files_deposited'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpub_comp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files_deposited'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpub_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles_deposited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpub_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles_deposited\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%m/%d/%y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cf6ba8e637d8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpub_comp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files_deposited'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpub_comp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files_deposited'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpub_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles_deposited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpub_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles_deposited\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%m/%d/%y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[1;32m    576\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0;32m--> 359\u001b[0;31m                          (data_string, format))\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         raise ValueError(\"unconverted data remains: %s\" %\n",
      "\u001b[0;31mValueError\u001b[0m: time data '2020-01-10' does not match format '%m/%d/%y'"
     ]
    }
   ],
   "source": [
    "#pub_comp['files_deposited'] = pub_comp['files_deposited'].fillna('')\n",
    "#pub_comp.files_deposited = pub_comp.files_deposited.apply(lambda x: x if x in '' else datetime.datetime.strptime(x, \"%m/%d/%y\").strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_comp.to_csv('batch_comprehensive_status.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28      2020-01-10\n",
       "206     2020-02-06\n",
       "469     2020-02-13\n",
       "1120    2018-09-24\n",
       "1471    2019-11-25\n",
       "1484    2019-12-26\n",
       "1776    2020-02-12\n",
       "1823    2019-11-25\n",
       "2290    2019-07-16\n",
       "2304    2019-12-15\n",
       "2349    2020-02-21\n",
       "2355    2020-02-12\n",
       "2461    2020-03-06\n",
       "Name: files_deposited, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_comp.loc[pub_comp['files_deposited'] != '', 'files_deposited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### PMC Section\n",
    "\n",
    "# loop batches of ~50 pmids for pmc status and tags check\n",
    "#pmc_rows = pmc_status.pmc_scrape(pubs_frame.pmid[0:50], variations, config.ncbi_login, config.ncbi_pass)\n",
    "#pmc_rows = []\n",
    "#batch = 50\n",
    "#for x in range(0, len(pubs_frame.pmid[0:101]), batch):\n",
    "#    pmc_rows.extend(pmc_status.pmc_scrape(pubs_frame.pmid[x:x+batch], variations, config.ncbi_login, config.ncbi_pass))\n",
    "\n",
    "#pmc_frame = pd.DataFrame(pmc_rows, columns=['pmid', 'pmc_status', 'pmc_tags', 'all_awards'])\n",
    "#pmc_frame.to_csv('DEV_batch_pmc_status.csv', index=False)\n",
    "# change blank values to nan- makes column merging easier\n",
    "#pmc_frame[pmc_frame == ''] = np.nan\n",
    "\n",
    "# get list of publications with red/grey/yellow pmc status to check on\n",
    "# nihms status\n",
    "#check_status = pmc_frame.pmid[pmc_frame['pmc_status'].isin(['2', '3', '4'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
